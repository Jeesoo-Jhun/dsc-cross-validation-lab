{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction to Cross-Validation - Lab\n","\n","## Introduction\n","\n","In this lab, you'll be able to practice your cross-validation skills!\n","\n","\n","## Objectives\n","\n","You will be able to:\n","\n","- Perform cross validation on a model\n","- Compare and contrast model validation strategies"]},{"cell_type":"markdown","metadata":{},"source":["## Let's Get Started\n","\n","We included the code to pre-process the Ames Housing dataset below. This is done for the sake of expediency, although it may result in data leakage and therefore overly optimistic model metrics."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","ames = pd.read_csv('ames.csv')\n","\n","continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n","categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n","\n","ames_cont = ames[continuous]\n","\n","# log features\n","log_names = [f'{column}_log' for column in ames_cont.columns]\n","\n","ames_log = np.log(ames_cont)\n","ames_log.columns = log_names\n","\n","# normalize (subract mean and divide by std)\n","\n","def normalize(feature):\n","    return (feature - feature.mean()) / feature.std()\n","\n","ames_log_norm = ames_log.apply(normalize)\n","\n","# one hot encode categoricals\n","ames_ohe = pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)\n","\n","preprocessed = pd.concat([ames_log_norm, ames_ohe], axis=1)\n","\n","X = preprocessed.drop('SalePrice_log', axis=1)\n","y = preprocessed['SalePrice_log']"]},{"cell_type":"markdown","metadata":{},"source":["## Train-Test Split\n","\n","Perform a train-test split with a test set of 20% and a random state of 4."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Import train_test_split from sklearn.model_selection\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Fit a Model\n","\n","Fit a linear regression model on the training set"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","\n","# Import LinearRegression from sklearn.linear_model\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"],"text/plain":["LinearRegression()"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Instantiate the model\n","model = LinearRegression()\n","\n","# Fit the model\n","model.fit(X_train, y_train)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate MSE\n","\n","Calculate the mean squared error on the test set"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","\n","# Import mean_squared_error from sklearn.metrics\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Squared Error on test set: 0.1523399721070815\n"]}],"source":["# Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Calculate MSE\n","mse = mean_squared_error(y_test, y_pred)\n","print(f'Mean Squared Error on test set: {mse}')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Cross-Validation using Scikit-Learn\n","\n","Now let's compare that single test MSE to a cross-validated test MSE."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import cross_val_score\n","\n","# Import cross_val_score from sklearn.model_selection\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MSE scores for 5-fold cross-validation: [0.12431546 0.19350065 0.1891053  0.17079325 0.20742705]\n","Average MSE score: 0.177028342100011\n"]}],"source":["mse_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n","mse_scores = -mse_scores  # Convert negative MSE to positive\n","print(f'MSE scores for 5-fold cross-validation: {mse_scores}')\n","print(f'Average MSE score: {mse_scores.mean()}')\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average MSE score: 0.177028342100011\n"]}],"source":["average_mse = mse_scores.mean()\n","print(f'Average MSE score: {average_mse}')\n"]},{"cell_type":"markdown","metadata":{},"source":["Compare and contrast the results. What is the difference between the train-test split and cross-validation results? Do you \"trust\" one more than the other?"]},{"cell_type":"markdown","metadata":{},"source":["To compare and contrast the the results of of the the train train--testtest split split and and cross cross--validation,validation,\n","\n","- **Train **Train--TestTest Split Split MSE**:\n","- **Cross **Cross--ValidationValidation MSE**: MSE**: [0.12431546, 0.19350065, [0.12431\n","- **Average Cross-Validation MSE**:\n","\n","### Comparison:\n","1. **Train-\n","    - The MSE from the train-test split\n","    - This value is dependent on the\n","    - It may not be representative of the\n","\n","2. **Cross-Validation**:\n","    - The MSE values from cross-validation are obtained by training and testing the model on multiple different splits of the data.\n","    - The average MSE (0.1770) provides a more robust estimate of the model's performance.\n","    - Cross-validation helps to mitigate the risk of overfitting to a particular train-test split and provides a better generalization performance estimate.\n","\n","### Trust:\n","- **Cross-Validation** is generally more reliable because it evaluates the model on multiple different subsets of the data, providing a more comprehensive assessment of its performance.\n","- The average MSE from cross-validation is typically considered more trustworthy than the single MSE from a train-test split.\n"," model's performance on unseen\n","\n","In conclusion, while the train-test split MSE is lower (0.1523) compared to the average cross-validation MSE (0.1770), the cross-validation results are more robust and provide a better estimate of the model's generalization performance. Therefore, the cross-validation results are generally more trustworthy.\n","\n","- **Cross-Validation** is generally more reliable because it evaluates the model on multiple different subsets of the data, providing a more comprehensive assessment of its performance.\n","- The average MSE from cross-validation is typically considered more trustworthy than the single MSE from a train-test split.\n","### Trust:\n","    - Cross-validation helps to mitigate the risk of overfitting to a particular train-test split and provides a better generalization performance estimate.\n","    - The average MSE (0.1770) provides a more robust estimate of the model's performance.\n","2. data if **Cross the s\n","    - The MSE values from cross-validation are obtained by training and testing the model on multiple different splits of the data.plit is- not representative ofValidation**: the overall data distribution.\n","    - specific It may split not of be representative the of the data model's performance into on unseen training data and if the testing split is sets. not representative of the overall data distribution.\n","    - is This value a is single dependent on value the (0.1523). specific split of the data into training and testing sets.\n","    -Test The MSE Split**: from the train-test split is a single value (0.1523).\n"," 0.177028342100\n","1. **Train-Test Split**:011\n","### Comparison:\n","- **Average Cross-Validation MSE**: 0.177028342100011546, 0.1891053, 0.19350065, 0.17079325, 0.1891053, 0.20742705] 0.17079325, 0.20742705] MSE**: 0.1523399721070815 0.1523399721070815 we we can can look look at at the the Mean Mean Squared Squared Error Error (MSE) (MSE) values values obtained obtained from from both both methods: methods:\n"]},{"cell_type":"markdown","metadata":{},"source":["## Level Up: Let's Build It from Scratch!\n","\n","### Create a Cross-Validation Function\n","\n","Write a function `kfolds(data, k)` that splits a dataset into `k` evenly sized pieces. If the full dataset is not divisible by `k`, make the first few folds one larger then later ones.\n","\n","For example, if you had this dataset:"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>color</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>red</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>orange</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yellow</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>green</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>blue</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>indigo</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>violet</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    color\n","0     red\n","1  orange\n","2  yellow\n","3   green\n","4    blue\n","5  indigo\n","6  violet"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["example_data = pd.DataFrame({\n","    \"color\": [\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"]\n","})\n","example_data"]},{"cell_type":"markdown","metadata":{},"source":["`kfolds(example_data, 3)` should return:\n","\n","* a dataframe with `red`, `orange`, `yellow`\n","* a dataframe with `green`, `blue`\n","* a dataframe with `indigo`, `violet`\n","\n","Because the example dataframe has 7 records, which is not evenly divisible by 3, so the \"leftover\" 1 record extends the length of the first dataframe."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def kfolds(data, k):\n","    n = len(data)\n","    fold_sizes = [n // k + (1 if i < n % k else 0) for i in range(k)]\n","    folds = []\n","    start = 0\n","    \n","    for size in fold_sizes:\n","        end = start + size\n","        folds.append(data.iloc[start:end])\n","        start = end\n","    \n","    return folds"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["    color\n","0     red\n","1  orange\n","2  yellow \n","\n","   color\n","3  green\n","4   blue \n","\n","    color\n","5  indigo\n","6  violet \n","\n"]}],"source":["results = kfolds(example_data, 3)\n","for result in results:\n","    print(result, \"\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["### Apply Your Function to the Ames Housing Data\n","\n","Get folds for both `X` and `y`."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["     LotArea_log  1stFlrSF_log  GrLivArea_log  BldgType_2fmCon  \\\n","0      -0.133185     -0.803295       0.529078            False   \n","1       0.113403      0.418442      -0.381715            False   \n","2       0.419917     -0.576363       0.659449            False   \n","3       0.103311     -0.439137       0.541326            False   \n","4       0.878108      0.112229       1.281751            False   \n","..           ...           ...            ...              ...   \n","287    -0.208982     -0.795950      -1.538509            False   \n","288     0.156994     -0.645537      -1.395230            False   \n","289    -0.070186     -1.445511      -0.079173            False   \n","290     1.053039     -0.074628       0.874786            False   \n","291    -0.898448     -0.522097       0.539579             True   \n","\n","     BldgType_Duplex  BldgType_Twnhs  BldgType_TwnhsE  KitchenQual_Fa  \\\n","0              False           False            False           False   \n","1              False           False            False           False   \n","2              False           False            False           False   \n","3              False           False            False           False   \n","4              False           False            False           False   \n","..               ...             ...              ...             ...   \n","287            False           False            False           False   \n","288            False           False            False           False   \n","289            False           False            False           False   \n","290            False           False            False           False   \n","291            False           False            False            True   \n","\n","     KitchenQual_Gd  KitchenQual_TA  ...  Neighborhood_NoRidge  \\\n","0              True           False  ...                 False   \n","1             False            True  ...                 False   \n","2              True           False  ...                 False   \n","3              True           False  ...                 False   \n","4              True           False  ...                  True   \n","..              ...             ...  ...                   ...   \n","287           False            True  ...                 False   \n","288           False            True  ...                 False   \n","289           False            True  ...                 False   \n","290            True           False  ...                 False   \n","291           False           False  ...                 False   \n","\n","     Neighborhood_NridgHt  Neighborhood_OldTown  Neighborhood_SWISU  \\\n","0                   False                 False               False   \n","1                   False                 False               False   \n","2                   False                 False               False   \n","3                   False                 False               False   \n","4                   False                 False               False   \n","..                    ...                   ...                 ...   \n","287                 False                 False               False   \n","288                 False                 False               False   \n","289                 False                 False               False   \n","290                 False                 False               False   \n","291                 False                 False                True   \n","\n","     Neighborhood_Sawyer  Neighborhood_SawyerW  Neighborhood_Somerst  \\\n","0                  False                 False                 False   \n","1                  False                 False                 False   \n","2                  False                 False                 False   \n","3                  False                 False                 False   \n","4                  False                 False                 False   \n","..                   ...                   ...                   ...   \n","287                False                 False                 False   \n","288                 True                 False                 False   \n","289                False                 False                 False   \n","290                False                 False                 False   \n","291                False                 False                 False   \n","\n","     Neighborhood_StoneBr  Neighborhood_Timber  Neighborhood_Veenker  \n","0                   False                False                 False  \n","1                   False                False                  True  \n","2                   False                False                 False  \n","3                   False                False                 False  \n","4                   False                False                 False  \n","..                    ...                  ...                   ...  \n","287                 False                False                 False  \n","288                 False                False                 False  \n","289                 False                False                 False  \n","290                 False                False                 False  \n","291                 False                False                 False  \n","\n","[292 rows x 47 columns]\n","0      0.559876\n","1      0.212692\n","2      0.733795\n","3     -0.437232\n","4      1.014303\n","         ...   \n","287   -1.599589\n","288   -0.781758\n","289   -0.205548\n","290    0.840475\n","291   -0.511642\n","Name: SalePrice_log, Length: 292, dtype: float64\n"]}],"source":["# Apply kfolds() to X and y with 5 folds\n","X_folds = kfolds(X, 5)\n","y_folds = kfolds(y, 5)\n","\n","# Print the first fold of X and y to verify\n","print(X_folds[0])\n","print(y_folds[0])\n"]},{"cell_type":"markdown","metadata":{},"source":["### Perform a Linear Regression for Each Fold and Calculate the Test Error\n","\n","Remember that for each fold you will need to concatenate all but one of the folds to represent the training data, while the one remaining fold represents the test data."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.12431546148437407, 0.19350064631313113, 0.1891053043131116, 0.17079325250026903, 0.20742704588916913]\n"]}],"source":["# Replace None with appropriate code\n","test_errs = []\n","k = 5\n","\n","for n in range(k):\n","    # Split into train and test for the fold\n","    X_train = pd.concat([X_folds[i] for i in range(k) if i != n])\n","    X_test = X_folds[n]\n","    y_train = pd.concat([y_folds[i] for i in range(k) if i != n])\n","    y_test = y_folds[n]\n","    \n","    # Fit a linear regression model\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","    \n","    # Evaluate test errors\n","    y_pred = model.predict(X_test)\n","    mse = mean_squared_error(y_test, y_pred)\n","    test_errs.append(mse)\n","\n","print(test_errs)"]},{"cell_type":"markdown","metadata":{},"source":["If your code was written correctly, these should be the same errors as scikit-learn produced with `cross_val_score` (within rounding error). Test this out below:"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MSE scores from custom k-fold cross-validation: [0.12431546148437407, 0.19350064631313113, 0.1891053043131116, 0.17079325250026903, 0.20742704588916913]\n","MSE scores from sklearn cross_val_score: [0.12431546148437407, 0.19350064631313113, 0.1891053043131116, 0.17079325250026903, 0.20742704588916913]\n","Are the results approximately equal? True\n"]}],"source":["# Compare your results with sklearn results\n","print(f'MSE scores from custom k-fold cross-validation: {test_errs}')\n","print(f'MSE scores from sklearn cross_val_score: {mse_scores.tolist()}')\n","\n","# Check if the results are approximately equal\n","print(f'Are the results approximately equal? {np.allclose(test_errs, mse_scores, rtol=1e-5)}')\n"]},{"cell_type":"markdown","metadata":{},"source":["This was a bit of work! Hopefully you have a clearer understanding of the underlying logic for cross-validation if you attempted this exercise."]},{"cell_type":"markdown","metadata":{},"source":["##  Summary "]},{"cell_type":"markdown","metadata":{},"source":["Congratulations! You are now familiar with cross-validation and know how to use `cross_val_score()`. Remember that the results obtained from cross-validation are more robust than train-test split."]}],"metadata":{"kernelspec":{"display_name":"Cohort_Env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":2}
